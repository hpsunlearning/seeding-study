{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from biom import Table, load_table\n",
    "import qiime2 as q2\n",
    "import pandas as pd\n",
    "from biom.util import biom_open\n",
    "from scipy.stats import sem\n",
    "from qiime2.plugins.feature_table.methods import rarefy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Processed Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the metadata from `../data/processed-data/metadata.qza` appeared to missing some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13516, 87)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2bt = q2.Artifact.load('../data/processed-data/table.qza')\n",
    "q2mf = q2.Metadata.load('../data/processed-data/metadata.qza')\n",
    "bt = q2bt.view(Table)\n",
    "mf = q2mf.to_dataframe()\n",
    "mf.shape # (Number of Samples, Number of Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193216, 13516)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.shape # (ASV, Number of Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12759"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bt.sum(axis='sample') > 1000) # count the number of smaples with more than 1000 reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7.94702397e+08)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demisons of data table (192457, 12759)\n",
      "total reads 794469124.0\n",
      "Average depth per sample (after filtering out <=1000 reads samples): 62267.35041931186\n",
      "Min depth per sample 1005.0\n",
      "Max depth per sample 765606.0\n",
      "SD depth per sample 62405.85234945933\n",
      "SE depth per sample 552.5022110091264\n",
      "Median depth per sample 41397.0\n"
     ]
    }
   ],
   "source": [
    "bt_mbbs = bt.copy()\n",
    "filt_ = bt_mbbs.ids()[bt_mbbs.sum(axis='sample') > 1000]\n",
    "bt_mbbs = bt_mbbs.filter(filt_)\n",
    "bt_mbbs = bt_mbbs.filter(bt_mbbs.ids('observation')[bt_mbbs.sum('observation') > 0],\n",
    "                         axis='observation') # tabel with samples have more than 1000 reads\n",
    "print('demisons of data table', bt_mbbs.shape)\n",
    "print('total reads', bt_mbbs.sum())\n",
    "print('Average depth per sample (after filtering out <=1000 reads samples):', np.mean(bt_mbbs.sum(axis='sample')))\n",
    "print('Min depth per sample', np.min(bt_mbbs.sum(axis='sample')))\n",
    "print('Max depth per sample', np.max(bt_mbbs.sum(axis='sample')))\n",
    "print('SD depth per sample', np.std(bt_mbbs.sum(axis='sample')))\n",
    "print('SE depth per sample', sem(bt_mbbs.sum(axis='sample')))\n",
    "print('Median depth per sample', np.median(bt_mbbs.sum(axis='sample')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the final curated metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jincheng/miniconda3/envs/qiime2-2019.7/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14784, 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_curated = pd.read_table('../data/processed-data/Metadata_Baby_Seeding_all_samples_final.txt', header = 0).dropna(1, how = 'all')\n",
    "# filter mf so that only samples in bt appears\n",
    "mf_curated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Possible           11133\n",
       "No-NoSeq            1200\n",
       "No-Replicates       1013\n",
       "No-LaneRunError      724\n",
       "No-misc              635\n",
       "No-control            79\n",
       "Name: manuscript_use, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_curated.manuscript_use.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the curated metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11212, 48)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the curated metadata, remove samples not in bt, and those with various issues\n",
    "mf_curated_f = mf_curated[mf_curated.sample_name.isin(bt.ids()) & ~mf_curated.manuscript_use.isin(['No-Replicates', 'No-LaneRunError', 'No-misc'])] \n",
    "mf_curated_f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the final filtered curated metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Possible      11133\n",
       "No-control       79\n",
       "Name: manuscript_use, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_curated_f.manuscript_use.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qiita_study', 'prep_name', 'run_name', '100nt_deblur', 'sequencing_id',\n",
       "       'baby_birth_date', 'baby_sex', 'birth_mode', 'birth_mode_ms',\n",
       "       'body_site_corrected', 'body_site_orig', 'body_site_type',\n",
       "       'collection_timestamp', 'country', 'current_abx',\n",
       "       'current_breast_feeding', 'current_formula', 'current_solids',\n",
       "       'date_sampling', 'date_sampling_category',\n",
       "       'date_sampling_category_days', 'date_sampling_category_days_continuous',\n",
       "       'description', 'elevation', 'empo_1', 'empo_2', 'empo_3', 'env_biome',\n",
       "       'env_feature', 'env_material', 'env_package', 'exclusive_breastfeed',\n",
       "       'familyid', 'familyid_unique', 'geo_loc_name', 'hospital_name',\n",
       "       'host_age', 'host_age_units', 'host_body_habitat',\n",
       "       'host_body_mass_index', 'host_body_product', 'host_body_site',\n",
       "       'host_common_name', 'host_height', 'host_height_units',\n",
       "       'host_scientific_name', 'host_subject_id', 'host_taxid', 'host_weight',\n",
       "       'host_weight_units', 'irb_institution', 'lane', 'latitude', 'longitude',\n",
       "       'manuscript_use', 'mom_baby', 'mother_abx_1st_trimester',\n",
       "       'mother_abx_1st_trimester_name', 'mother_abx_2nd_trimester',\n",
       "       'mother_abx_2nd_trimester_name', 'mother_abx_3rd_trimester',\n",
       "       'mother_abx_3rd_trimester_name', 'mother_abx_perinatal',\n",
       "       'mother_abx_perinatal_name', 'mother_prenatal_gbs', 'mother_race',\n",
       "       'orig_sampleid', 'physical_specimen_location', 'primer_plate',\n",
       "       'project_name', 'qiita_study_id', 'real_sampling_time', 'run',\n",
       "       'sample_type', 'scientific_name', 'seeding_method', 'seqcount', 'sex',\n",
       "       'state', 'study_id', 'subjectid', 'subjectid_unique', 'taxon_id',\n",
       "       'title', 'tube_id', 'village', 'well'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_name', 'seqcount', 'orig_sampleid', 'study_id', 'primer_plate',\n",
       "       'well', 'lane', 'run', 'hospital_name', 'village', 'state', 'country',\n",
       "       'irb_institution', 'project_name', 'body_site_orig',\n",
       "       'body_site_corrected', 'body_site_type', 'familyid', 'familyid_unique',\n",
       "       'mom_baby', 'subjectid', 'subjectid_unique', 'date_sampling',\n",
       "       'real_sampling_time', 'date_sampling_category',\n",
       "       'date_sampling_category_days', 'date_sampling_category_days_continuous',\n",
       "       'baby_sex', 'birth_mode', 'seeding_method', 'baby_birth_date',\n",
       "       'current_abx', 'mother_prenatal_gbs', 'mother_abx_perinatal',\n",
       "       'mother_abx_perinatal_name', 'mother_abx_1st_trimester',\n",
       "       'mother_abx_1st_trimester_name', 'mother_abx_2nd_trimester',\n",
       "       'mother_abx_2nd_trimester_name', 'mother_abx_3rd_trimester',\n",
       "       'mother_abx_3rd_trimester_name', 'mother_race',\n",
       "       'current_breast_feeding', 'current_formula', 'current_solids',\n",
       "       'exclusive_breastfeed', 'birth_mode_ms', 'manuscript_use'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_curated_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10894.0    11287\n",
       "11648.0     1044\n",
       "1718.0       505\n",
       "Name: qiita_study, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.qiita_study.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10894.0    9899\n",
       "10249.0     696\n",
       "12261.0     452\n",
       "1718.0      165\n",
       "Name: study_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_curated_f.study_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feces            2850\n",
       "Mouth            2091\n",
       "Right_Forearm    1505\n",
       "Forehead         1281\n",
       "Nose             1199\n",
       "Vagina           1064\n",
       "Right_Areola      947\n",
       "Right_Hand        916\n",
       "Anus              307\n",
       "Forearm           304\n",
       "Breast_Milk       146\n",
       "Right_Foot         85\n",
       "Control            79\n",
       "Left_Hand          54\n",
       "Breast              8\n",
       "Name: body_site_corrected, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.body_site_corrected.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feces            2323\n",
       "Mouth            1801\n",
       "Right_Forearm    1440\n",
       "Forehead         1197\n",
       "Nose             1140\n",
       "Vagina            905\n",
       "Right_Hand        832\n",
       "Right_Areola      714\n",
       "Forearm           304\n",
       "Anus              221\n",
       "Breast_Milk       141\n",
       "Right_Foot         85\n",
       "Control            79\n",
       "Left_Hand          22\n",
       "Breast              8\n",
       "Name: body_site_corrected, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_curated_f.body_site_corrected.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vag       102\n",
       "CS         52\n",
       "CSseed     28\n",
       "Name: birth_mode_ms, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.groupby('familyid_unique').agg({'birth_mode_ms':'first'}).birth_mode_ms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of families from each birth mode:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vag       101\n",
       "CS         52\n",
       "CSseed     28\n",
       "Name: birth_mode_ms, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of families from each birth mode:\")\n",
    "mf_curated_f.groupby('familyid_unique').agg({'birth_mode_ms':'first'}).birth_mode_ms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of babies from each birth mode:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vag       99\n",
       "CS        49\n",
       "CSseed    28\n",
       "Name: birth_mode_ms, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of babies from each birth mode:\")\n",
    "mf_curated_f[mf_curated_f.mom_baby.eq('Baby')].groupby('familyid_unique').agg({'birth_mode_ms':'first'}).birth_mode_ms.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House keeping on the curated final metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jincheng/miniconda3/envs/qiime2-2019.7/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# change right_forearm to forearm for all samples\n",
    "mf_curated_f.loc[mf_curated_f.body_site_corrected == 'Right_Forearm', 'body_site_corrected'] = 'Forearm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Baby', 'No-control', 'Control'): 1,\n",
       " ('Baby', 'Possible', 'Anus'): 85,\n",
       " ('Baby', 'Possible', 'Feces'): 1557,\n",
       " ('Baby', 'Possible', 'Forearm'): 896,\n",
       " ('Baby', 'Possible', 'Forehead'): 638,\n",
       " ('Baby', 'Possible', 'Left_Hand'): 11,\n",
       " ('Baby', 'Possible', 'Mouth'): 928,\n",
       " ('Baby', 'Possible', 'Nose'): 611,\n",
       " ('Baby', 'Possible', 'Right_Foot'): 42,\n",
       " ('Baby', 'Possible', 'Right_Hand'): 457,\n",
       " ('Baby', 'Possible', 'Vagina'): 11,\n",
       " ('Mom', 'Possible', 'Anus'): 130,\n",
       " ('Mom', 'Possible', 'Breast'): 8,\n",
       " ('Mom', 'Possible', 'Breast_Milk'): 141,\n",
       " ('Mom', 'Possible', 'Feces'): 766,\n",
       " ('Mom', 'Possible', 'Forearm'): 848,\n",
       " ('Mom', 'Possible', 'Forehead'): 559,\n",
       " ('Mom', 'Possible', 'Left_Hand'): 11,\n",
       " ('Mom', 'Possible', 'Mouth'): 873,\n",
       " ('Mom', 'Possible', 'Nose'): 529,\n",
       " ('Mom', 'Possible', 'Right_Areola'): 714,\n",
       " ('Mom', 'Possible', 'Right_Foot'): 43,\n",
       " ('Mom', 'Possible', 'Right_Hand'): 375,\n",
       " ('Mom', 'Possible', 'Vagina'): 888}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_per = {bs_:mfbs.dropna(subset=['subjectid_unique',\n",
    "                                     'date_sampling_category_days_continuous'])\n",
    "           for bs_, mfbs in mf_curated_f.groupby(['mom_baby', 'manuscript_use', 'body_site_corrected'])}\n",
    "{k:v.shape[0] for k,v in map_per.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_curated_f.set_index('sample_name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Baby', 'Feces')\n",
      "(1391, 48)\n",
      "('Baby', 'Feces') 0-2\n",
      "(428, 48)\n",
      "('Baby', 'Feces') 17-26\n",
      "(157, 48)\n",
      "('Baby', 'Feces') 2-4\n",
      "(212, 48)\n",
      "('Baby', 'Feces') 26-51\n",
      "(347, 48)\n",
      "('Baby', 'Feces') 4-17\n",
      "(247, 48)\n",
      "('Baby', 'Mouth')\n",
      "(926, 48)\n",
      "('Baby', 'Mouth') 0-2\n",
      "(390, 48)\n",
      "('Baby', 'Mouth') 17-26\n",
      "(76, 48)\n",
      "('Baby', 'Mouth') 2-4\n",
      "(164, 48)\n",
      "('Baby', 'Mouth') 26-51\n",
      "(158, 48)\n",
      "('Baby', 'Mouth') 4-17\n",
      "(138, 48)\n",
      "('Baby', 'Forearm')\n",
      "(894, 48)\n",
      "('Baby', 'Forearm') 0-2\n",
      "(372, 48)\n",
      "('Baby', 'Forearm') 17-26\n",
      "(63, 48)\n",
      "('Baby', 'Forearm') 2-4\n",
      "(161, 48)\n",
      "('Baby', 'Forearm') 26-51\n",
      "(176, 48)\n",
      "('Baby', 'Forearm') 4-17\n",
      "(122, 48)\n",
      "('Mom', 'Vagina')\n",
      "(888, 47)\n",
      "('Mom', 'Feces')\n",
      "(765, 47)\n",
      "('Mom', 'Mouth')\n",
      "(873, 47)\n",
      "('Mom', 'Forearm')\n",
      "(848, 47)\n",
      "('Mom', 'Nose')\n",
      "(529, 47)\n",
      "('Mom', 'Right_Areola')\n",
      "(714, 47)\n"
     ]
    }
   ],
   "source": [
    "# use for now\n",
    "use_ = [('Baby', 'Feces'),\n",
    "        ('Baby', 'Mouth'),\n",
    "        ('Baby', 'Forearm'),\n",
    "        ('Mom', 'Vagina'),\n",
    "        ('Mom', 'Feces'),\n",
    "        ('Mom', 'Mouth'),\n",
    "        ('Mom', 'Forearm'),\n",
    "       ('Mom', 'Nose'),\n",
    "       ('Mom', 'Right_Areola')]\n",
    "\n",
    "map_per = {bs_:mfbs.dropna(subset=['subjectid_unique',\n",
    "                                     'date_sampling_category_days_continuous'])\n",
    "           for bs_, mfbs in mf_curated_f.groupby(['mom_baby', 'body_site_corrected'])}\n",
    "for mb_bs in use_:\n",
    "    # get subset\n",
    "    mf_mbbs = map_per[mb_bs].drop(['body_site_corrected'], axis=1)\n",
    "    mf_mbbs = mf_mbbs[mf_mbbs.date_sampling_category_days_continuous <= 360]\n",
    "    bt_mbbs = bt.copy()\n",
    "    out_ = os.path.join('../data/split-data',\n",
    "                        '-'.join(list(mb_bs)))\n",
    "    #filter\n",
    "    bt_mbbs = bt_mbbs.filter(mf_mbbs.index)\n",
    "    bt_mbbs = bt_mbbs.filter(bt_mbbs.ids('observation')[bt_mbbs.sum('observation') > 0],\n",
    "                             axis='observation')\n",
    "    mf_mbbs = mf_mbbs.reindex(bt_mbbs.ids())\n",
    "\n",
    "    # life-stage groupings\n",
    "    if mb_bs[0] == 'Baby':\n",
    "        life_stage = {'0-2':[-2, 14],\n",
    "                      '2-4':[14, 30],\n",
    "                      '4-17':[30, 120],\n",
    "                      '17-26':[120, 180],\n",
    "                      '26-51':[180, 360],\n",
    "                      '51-end':[360, 6000]}\n",
    "        # invert the dict\n",
    "        life_stage = {d:ls for ls, dr in life_stage.items()\n",
    "                      for d in range(dr[0]+1, dr[1]+1)}\n",
    "        # make lif-stage col.\n",
    "        mf_mbbs.date_sampling_category_days_continuous = mf_mbbs.date_sampling_category_days_continuous.astype(float)\n",
    "        mf_mbbs['life_stage'] = [life_stage[d]\n",
    "                                 for d in mf_mbbs.date_sampling_category_days_continuous]\n",
    "    # make subject id\n",
    "    mf_mbbs['host_subject_id'] = mf_mbbs.subjectid_unique.values\n",
    "\n",
    "    # save an write\n",
    "    q2bt_mbbs =  q2.Artifact.import_data('FeatureTable[Frequency]', bt_mbbs)\n",
    "    q2mf_mbbs = q2.Metadata(mf_mbbs)\n",
    "    \n",
    "    # write out\n",
    "    os.mkdir(out_)\n",
    "    q2bt_mbbs.save(os.path.join(out_,'table.qza'))\n",
    "    q2mf_mbbs.save(os.path.join(out_,'metadata.qza'))\n",
    "    mf_mbbs.to_csv(os.path.join(out_,'metadata.tsv'), sep='\\t')\n",
    "    with biom_open(os.path.join(out_,'table.biom'), 'w') as f:\n",
    "        bt_mbbs.to_hdf5(f, \"bs_type\")\n",
    "    print(mb_bs)\n",
    "    print(mf_mbbs.shape)\n",
    "    \n",
    "    # split by life-stage\n",
    "    if mb_bs[0] == 'Baby':\n",
    "        for ls_, mf_mbbs_ls in mf_mbbs.groupby('life_stage'):\n",
    "            out_ls = out_ + '-%s' % (ls_)\n",
    "            # subset table\n",
    "            bt_mbbs_ls = bt_mbbs.copy()\n",
    "            bt_mbbs_ls = bt_mbbs_ls.filter(mf_mbbs_ls.index)\n",
    "            bt_mbbs_ls = bt_mbbs_ls.filter(bt_mbbs_ls.ids('observation')[bt_mbbs_ls.sum('observation') > 0],\n",
    "                                           axis='observation')\n",
    "            mf_mbbs_ls = mf_mbbs_ls.reindex(bt_mbbs_ls.ids())\n",
    "            # export all\n",
    "            os.mkdir(out_ls)\n",
    "            # save an write\n",
    "            q2bt_mbbs_ls =  q2.Artifact.import_data('FeatureTable[Frequency]', bt_mbbs_ls)\n",
    "            q2mf_mbbs_ls = q2.Metadata(mf_mbbs_ls)\n",
    "            # write\n",
    "            q2bt_mbbs_ls.save(os.path.join(out_ls,'table.qza'))\n",
    "            q2mf_mbbs_ls.save(os.path.join(out_ls,'metadata.qza'))\n",
    "            mf_mbbs_ls.to_csv(os.path.join(out_ls,'metadata.tsv'), sep='\\t')\n",
    "            with biom_open(os.path.join(out_ls,'table.biom'), 'w') as f:\n",
    "                bt_mbbs_ls.to_hdf5(f, \"bs_type\")\n",
    "            print(mb_bs, ls_)\n",
    "            print(mf_mbbs_ls.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rarefy the feature tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: mom_fecal\n",
      "Rarefy-depth 5000\n",
      "Starting: mom_oral\n",
      "Rarefy-depth 5000\n",
      "Starting: mom_skin\n",
      "Rarefy-depth 5000\n",
      "Starting: mom_vagina\n",
      "Rarefy-depth 5000\n",
      "Starting: mom_areola\n",
      "Rarefy-depth 5000\n",
      "Starting: mom_nose\n",
      "Rarefy-depth 5000\n",
      "Starting: baby_fecal\n",
      "Rarefy-depth 5000\n",
      "Starting: baby_oral\n",
      "Rarefy-depth 5000\n",
      "Starting: baby_skin\n",
      "Rarefy-depth 5000\n"
     ]
    }
   ],
   "source": [
    "# tables for import\n",
    "tables_ = {'mom_fecal':'../data/split-data/Mom-Feces',\n",
    "            'mom_oral':'../data/split-data/Mom-Mouth',\n",
    "            'mom_skin':'../data/split-data/Mom-Forearm',\n",
    "            'mom_vagina':'../data/split-data/Mom-Vagina/',\n",
    "          'mom_areola':'../data/split-data/Mom-Right_Areola',\n",
    "          'mom_nose':'../data/split-data/Mom-Nose',\n",
    "          'baby_fecal':'../data/split-data/Baby-Feces',\n",
    "            'baby_oral':'../data/split-data/Baby-Mouth',\n",
    "            'baby_skin':'../data/split-data/Baby-Forearm'}\n",
    "\n",
    "# get each table and run rarefication\n",
    "for k_, path_ in tables_.items():\n",
    "    print('Starting: %s' % k_)\n",
    "    # get table(s)\n",
    "    table_ = load_table(os.path.join(path_, 'table.biom'))\n",
    "    table_ = pd.DataFrame(table_.matrix_data.toarray(),\n",
    "                          table_.ids('observation'),\n",
    "                          table_.ids()).T\n",
    "    tq2able_ = q2.Artifact.import_data('FeatureTable[Frequency]', table_)\n",
    "    # rar depth (hard set to 5000)\n",
    "    #rar_depth = int(max(table_.sum(1).min(), 1250))\n",
    "    rar_depth = 5000\n",
    "    print('Rarefy-depth %i' % rar_depth)\n",
    "    # run rare\n",
    "    table_rar = rarefy(tq2able_, rar_depth).rarefied_table\n",
    "    table_rar.save(os.path.join(path_, 'rarefy-table.qza'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset for additional song bird run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Feces', 0.0, 'CS'): 12,\n",
       " ('Feces', 0.0, 'CSseed'): 13,\n",
       " ('Feces', 0.0, 'Vag'): 48,\n",
       " ('Feces', 1.0, 'CS'): 20,\n",
       " ('Feces', 1.0, 'CSseed'): 10,\n",
       " ('Feces', 1.0, 'Vag'): 45,\n",
       " ('Feces', 2.0, 'CS'): 12,\n",
       " ('Feces', 2.0, 'CSseed'): 20,\n",
       " ('Feces', 2.0, 'Vag'): 47,\n",
       " ('Feces', 7.0, 'CS'): 23,\n",
       " ('Feces', 7.0, 'CSseed'): 20,\n",
       " ('Feces', 7.0, 'Vag'): 67,\n",
       " ('Feces', 14.0, 'CS'): 17,\n",
       " ('Feces', 14.0, 'CSseed'): 17,\n",
       " ('Feces', 14.0, 'Vag'): 57,\n",
       " ('Feces', 21.0, 'CS'): 13,\n",
       " ('Feces', 21.0, 'CSseed'): 10,\n",
       " ('Feces', 21.0, 'Vag'): 48,\n",
       " ('Feces', 30.0, 'CS'): 42,\n",
       " ('Feces', 30.0, 'CSseed'): 20,\n",
       " ('Feces', 30.0, 'Vag'): 79,\n",
       " ('Feces', 60.0, 'CS'): 31,\n",
       " ('Feces', 60.0, 'CSseed'): 18,\n",
       " ('Feces', 60.0, 'Vag'): 39,\n",
       " ('Feces', 90.0, 'CS'): 28,\n",
       " ('Feces', 90.0, 'CSseed'): 8,\n",
       " ('Feces', 90.0, 'Vag'): 39,\n",
       " ('Feces', 120.0, 'CS'): 27,\n",
       " ('Feces', 120.0, 'CSseed'): 16,\n",
       " ('Feces', 120.0, 'Vag'): 41,\n",
       " ('Feces', 150.0, 'CS'): 25,\n",
       " ('Feces', 150.0, 'CSseed'): 9,\n",
       " ('Feces', 150.0, 'Vag'): 37,\n",
       " ('Feces', 180.0, 'CS'): 28,\n",
       " ('Feces', 180.0, 'CSseed'): 15,\n",
       " ('Feces', 180.0, 'Vag'): 43,\n",
       " ('Feces', 210.0, 'CS'): 23,\n",
       " ('Feces', 210.0, 'CSseed'): 5,\n",
       " ('Feces', 210.0, 'Vag'): 33,\n",
       " ('Feces', 240.0, 'CS'): 22,\n",
       " ('Feces', 240.0, 'CSseed'): 5,\n",
       " ('Feces', 240.0, 'Vag'): 31,\n",
       " ('Feces', 270.0, 'CS'): 21,\n",
       " ('Feces', 270.0, 'CSseed'): 2,\n",
       " ('Feces', 270.0, 'Vag'): 30,\n",
       " ('Feces', 300.0, 'CS'): 17,\n",
       " ('Feces', 300.0, 'CSseed'): 4,\n",
       " ('Feces', 300.0, 'Vag'): 29,\n",
       " ('Feces', 330.0, 'CS'): 20,\n",
       " ('Feces', 330.0, 'CSseed'): 5,\n",
       " ('Feces', 330.0, 'Vag'): 28,\n",
       " ('Feces', 360.0, 'CS'): 25,\n",
       " ('Feces', 360.0, 'CSseed'): 14,\n",
       " ('Feces', 360.0, 'Vag'): 33,\n",
       " ('Feces', 390.0, 'CS'): 1,\n",
       " ('Feces', 390.0, 'Vag'): 3,\n",
       " ('Feces', 420.0, 'CS'): 8,\n",
       " ('Feces', 420.0, 'Vag'): 15,\n",
       " ('Feces', 450.0, 'CS'): 2,\n",
       " ('Feces', 450.0, 'Vag'): 3,\n",
       " ('Feces', 480.0, 'CS'): 7,\n",
       " ('Feces', 480.0, 'Vag'): 12,\n",
       " ('Feces', 510.0, 'CS'): 2,\n",
       " ('Feces', 510.0, 'Vag'): 3,\n",
       " ('Feces', 540.0, 'CS'): 8,\n",
       " ('Feces', 540.0, 'Vag'): 10,\n",
       " ('Feces', 570.0, 'CS'): 2,\n",
       " ('Feces', 570.0, 'Vag'): 5,\n",
       " ('Feces', 600.0, 'CS'): 5,\n",
       " ('Feces', 600.0, 'Vag'): 10,\n",
       " ('Feces', 630.0, 'CS'): 2,\n",
       " ('Feces', 630.0, 'Vag'): 5,\n",
       " ('Feces', 660.0, 'CS'): 4,\n",
       " ('Feces', 660.0, 'Vag'): 7,\n",
       " ('Feces', 690.0, 'CS'): 2,\n",
       " ('Feces', 690.0, 'Vag'): 3,\n",
       " ('Feces', 720.0, 'CS'): 3,\n",
       " ('Feces', 720.0, 'Vag'): 4,\n",
       " ('Feces', 750.0, 'CS'): 2,\n",
       " ('Feces', 750.0, 'Vag'): 6,\n",
       " ('Feces', 780.0, 'CS'): 3,\n",
       " ('Feces', 780.0, 'Vag'): 4,\n",
       " ('Feces', 810.0, 'CS'): 3,\n",
       " ('Feces', 810.0, 'Vag'): 4,\n",
       " ('Feces', 840.0, 'CS'): 2,\n",
       " ('Feces', 870.0, 'CS'): 3,\n",
       " ('Feces', 870.0, 'Vag'): 3,\n",
       " ('Feces', 900.0, 'CS'): 1,\n",
       " ('Feces', 930.0, 'CS'): 2,\n",
       " ('Feces', 930.0, 'Vag'): 2,\n",
       " ('Feces', 960.0, 'CS'): 1,\n",
       " ('Feces', 990.0, 'CS'): 2,\n",
       " ('Feces', 990.0, 'Vag'): 1,\n",
       " ('Feces', 1050.0, 'Vag'): 1,\n",
       " ('Forearm', 0.0, 'CS'): 8,\n",
       " ('Forearm', 0.0, 'CSseed'): 16,\n",
       " ('Forearm', 0.0, 'Vag'): 38,\n",
       " ('Forearm', 1.0, 'CS'): 10,\n",
       " ('Forearm', 1.0, 'CSseed'): 12,\n",
       " ('Forearm', 1.0, 'Vag'): 41,\n",
       " ('Forearm', 2.0, 'CS'): 14,\n",
       " ('Forearm', 2.0, 'CSseed'): 16,\n",
       " ('Forearm', 2.0, 'Vag'): 39,\n",
       " ('Forearm', 7.0, 'CS'): 18,\n",
       " ('Forearm', 7.0, 'CSseed'): 15,\n",
       " ('Forearm', 7.0, 'Vag'): 54,\n",
       " ('Forearm', 14.0, 'CS'): 20,\n",
       " ('Forearm', 14.0, 'CSseed'): 15,\n",
       " ('Forearm', 14.0, 'Vag'): 56,\n",
       " ('Forearm', 21.0, 'CS'): 15,\n",
       " ('Forearm', 21.0, 'CSseed'): 8,\n",
       " ('Forearm', 21.0, 'Vag'): 49,\n",
       " ('Forearm', 30.0, 'CS'): 19,\n",
       " ('Forearm', 30.0, 'CSseed'): 18,\n",
       " ('Forearm', 30.0, 'Vag'): 52,\n",
       " ('Forearm', 60.0, 'CS'): 17,\n",
       " ('Forearm', 60.0, 'CSseed'): 14,\n",
       " ('Forearm', 60.0, 'Vag'): 20,\n",
       " ('Forearm', 90.0, 'CS'): 7,\n",
       " ('Forearm', 90.0, 'CSseed'): 6,\n",
       " ('Forearm', 90.0, 'Vag'): 15,\n",
       " ('Forearm', 120.0, 'CS'): 14,\n",
       " ('Forearm', 120.0, 'CSseed'): 11,\n",
       " ('Forearm', 120.0, 'Vag'): 18,\n",
       " ('Forearm', 150.0, 'CS'): 7,\n",
       " ('Forearm', 150.0, 'CSseed'): 3,\n",
       " ('Forearm', 150.0, 'Vag'): 10,\n",
       " ('Forearm', 180.0, 'CS'): 14,\n",
       " ('Forearm', 180.0, 'CSseed'): 11,\n",
       " ('Forearm', 180.0, 'Vag'): 18,\n",
       " ('Forearm', 210.0, 'CS'): 11,\n",
       " ('Forearm', 210.0, 'CSseed'): 4,\n",
       " ('Forearm', 210.0, 'Vag'): 15,\n",
       " ('Forearm', 240.0, 'CS'): 11,\n",
       " ('Forearm', 240.0, 'CSseed'): 2,\n",
       " ('Forearm', 240.0, 'Vag'): 16,\n",
       " ('Forearm', 270.0, 'CS'): 12,\n",
       " ('Forearm', 270.0, 'CSseed'): 1,\n",
       " ('Forearm', 270.0, 'Vag'): 12,\n",
       " ('Forearm', 300.0, 'CS'): 13,\n",
       " ('Forearm', 300.0, 'CSseed'): 3,\n",
       " ('Forearm', 300.0, 'Vag'): 9,\n",
       " ('Forearm', 330.0, 'CS'): 13,\n",
       " ('Forearm', 330.0, 'CSseed'): 3,\n",
       " ('Forearm', 330.0, 'Vag'): 11,\n",
       " ('Forearm', 360.0, 'CS'): 15,\n",
       " ('Forearm', 360.0, 'CSseed'): 10,\n",
       " ('Forearm', 360.0, 'Vag'): 15,\n",
       " ('Forearm', 450.0, 'Vag'): 1,\n",
       " ('Forearm', 480.0, 'Vag'): 1,\n",
       " ('Mouth', 0.0, 'CS'): 8,\n",
       " ('Mouth', 0.0, 'CSseed'): 19,\n",
       " ('Mouth', 0.0, 'Vag'): 40,\n",
       " ('Mouth', 1.0, 'CS'): 10,\n",
       " ('Mouth', 1.0, 'CSseed'): 17,\n",
       " ('Mouth', 1.0, 'Vag'): 42,\n",
       " ('Mouth', 2.0, 'CS'): 14,\n",
       " ('Mouth', 2.0, 'CSseed'): 20,\n",
       " ('Mouth', 2.0, 'Vag'): 42,\n",
       " ('Mouth', 7.0, 'CS'): 19,\n",
       " ('Mouth', 7.0, 'CSseed'): 20,\n",
       " ('Mouth', 7.0, 'Vag'): 49,\n",
       " ('Mouth', 14.0, 'CS'): 20,\n",
       " ('Mouth', 14.0, 'CSseed'): 18,\n",
       " ('Mouth', 14.0, 'Vag'): 52,\n",
       " ('Mouth', 21.0, 'CS'): 14,\n",
       " ('Mouth', 21.0, 'CSseed'): 11,\n",
       " ('Mouth', 21.0, 'Vag'): 47,\n",
       " ('Mouth', 30.0, 'CS'): 20,\n",
       " ('Mouth', 30.0, 'CSseed'): 20,\n",
       " ('Mouth', 30.0, 'Vag'): 52,\n",
       " ('Mouth', 60.0, 'CS'): 17,\n",
       " ('Mouth', 60.0, 'CSseed'): 19,\n",
       " ('Mouth', 60.0, 'Vag'): 21,\n",
       " ('Mouth', 90.0, 'CS'): 12,\n",
       " ('Mouth', 90.0, 'CSseed'): 10,\n",
       " ('Mouth', 90.0, 'Vag'): 12,\n",
       " ('Mouth', 120.0, 'CS'): 14,\n",
       " ('Mouth', 120.0, 'CSseed'): 16,\n",
       " ('Mouth', 120.0, 'Vag'): 17,\n",
       " ('Mouth', 150.0, 'CS'): 8,\n",
       " ('Mouth', 150.0, 'CSseed'): 10,\n",
       " ('Mouth', 150.0, 'Vag'): 13,\n",
       " ('Mouth', 180.0, 'CS'): 13,\n",
       " ('Mouth', 180.0, 'CSseed'): 15,\n",
       " ('Mouth', 180.0, 'Vag'): 17,\n",
       " ('Mouth', 210.0, 'CS'): 8,\n",
       " ('Mouth', 210.0, 'CSseed'): 7,\n",
       " ('Mouth', 210.0, 'Vag'): 13,\n",
       " ('Mouth', 240.0, 'CS'): 9,\n",
       " ('Mouth', 240.0, 'CSseed'): 5,\n",
       " ('Mouth', 240.0, 'Vag'): 11,\n",
       " ('Mouth', 270.0, 'CS'): 9,\n",
       " ('Mouth', 270.0, 'CSseed'): 1,\n",
       " ('Mouth', 270.0, 'Vag'): 10,\n",
       " ('Mouth', 300.0, 'CS'): 9,\n",
       " ('Mouth', 300.0, 'CSseed'): 5,\n",
       " ('Mouth', 300.0, 'Vag'): 8,\n",
       " ('Mouth', 330.0, 'CS'): 9,\n",
       " ('Mouth', 330.0, 'CSseed'): 5,\n",
       " ('Mouth', 330.0, 'Vag'): 8,\n",
       " ('Mouth', 360.0, 'CS'): 13,\n",
       " ('Mouth', 360.0, 'CSseed'): 14,\n",
       " ('Mouth', 360.0, 'Vag'): 14,\n",
       " ('Mouth', 450.0, 'Vag'): 1,\n",
       " ('Mouth', 480.0, 'Vag'): 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v.shape[0] for k, v in \n",
    " mf_curated_f[(mf_curated_f.mom_baby==\"Baby\") & \n",
    "              (mf_curated_f.body_site_corrected.isin(['Feces', 'Mouth', 'Forearm']))\n",
    "             ].groupby(['body_site_corrected', 'date_sampling_category_days_continuous', 'birth_mode_ms'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Baby', 'Feces') 2.0\n",
      "(79, 47)\n",
      "('Baby', 'Feces') 30.0\n",
      "(141, 47)\n",
      "('Baby', 'Feces') 120.0\n",
      "(84, 47)\n",
      "('Baby', 'Feces') 180.0\n",
      "(86, 47)\n",
      "('Baby', 'Mouth') 2.0\n",
      "(76, 47)\n",
      "('Baby', 'Mouth') 30.0\n",
      "(92, 47)\n",
      "('Baby', 'Mouth') 120.0\n",
      "(47, 47)\n",
      "('Baby', 'Mouth') 180.0\n",
      "(45, 47)\n",
      "('Baby', 'Forearm') 2.0\n",
      "(69, 47)\n",
      "('Baby', 'Forearm') 30.0\n",
      "(89, 47)\n",
      "('Baby', 'Forearm') 120.0\n",
      "(43, 47)\n",
      "('Baby', 'Forearm') 180.0\n",
      "(43, 47)\n"
     ]
    }
   ],
   "source": [
    "# use for now\n",
    "use_ = [('Baby', 'Feces'),\n",
    "        ('Baby', 'Mouth'),\n",
    "        ('Baby', 'Forearm')]\n",
    "\n",
    "map_per = {bs_:mfbs[mfbs.date_sampling_category_days_continuous.isin(['2', '30', '120', '180'])]\n",
    "           for bs_, mfbs in mf_curated_f.groupby(['mom_baby', 'body_site_corrected'])}\n",
    "os.mkdir('../data/diff-analysis-new')\n",
    "for mb_bs in use_:\n",
    "    # get subset\n",
    "    mf_mbbs = map_per[mb_bs].drop(['body_site_corrected'], axis=1)\n",
    "    bt_mbbs = bt.copy()\n",
    "    out_ = os.path.join('../data/diff-analysis-new',\n",
    "                        '-'.join(list(mb_bs)))\n",
    "    #filter\n",
    "    bt_mbbs = bt_mbbs.filter(mf_mbbs.index)\n",
    "    bt_mbbs = bt_mbbs.filter(bt_mbbs.ids('observation')[bt_mbbs.sum('observation') > 0],\n",
    "                             axis='observation')\n",
    "    mf_mbbs = mf_mbbs.reindex(bt_mbbs.ids())\n",
    "\n",
    "    # make subject id\n",
    "    mf_mbbs['host_subject_id'] = mf_mbbs.subjectid_unique.values\n",
    "    \n",
    "    # split by life-stage\n",
    "    if mb_bs[0] == 'Baby':\n",
    "        for ls_, mf_mbbs_ls in mf_mbbs.groupby('date_sampling_category_days_continuous'):\n",
    "            out_ls = out_ + '-%s' % (ls_)\n",
    "            # subset table\n",
    "            bt_mbbs_ls = bt_mbbs.copy()\n",
    "            bt_mbbs_ls = bt_mbbs_ls.filter(mf_mbbs_ls.index)\n",
    "            bt_mbbs_ls = bt_mbbs_ls.filter(bt_mbbs_ls.ids('observation')[bt_mbbs_ls.sum('observation') > 0],\n",
    "                                           axis='observation')\n",
    "            mf_mbbs_ls = mf_mbbs_ls.reindex(bt_mbbs_ls.ids())\n",
    "            # export all\n",
    "            os.mkdir(out_ls)\n",
    "            # save an write\n",
    "            q2bt_mbbs_ls =  q2.Artifact.import_data('FeatureTable[Frequency]', bt_mbbs_ls)\n",
    "            q2mf_mbbs_ls = q2.Metadata(mf_mbbs_ls)\n",
    "            # write\n",
    "            q2bt_mbbs_ls.save(os.path.join(out_ls,'table.qza'))\n",
    "            q2mf_mbbs_ls.save(os.path.join(out_ls,'metadata.qza'))\n",
    "            mf_mbbs_ls.to_csv(os.path.join(out_ls,'metadata.tsv'), sep='\\t')\n",
    "            with biom_open(os.path.join(out_ls,'table.biom'), 'w') as f:\n",
    "                bt_mbbs_ls.to_hdf5(f, \"bs_type\")\n",
    "            print(mb_bs, ls_)\n",
    "            print(mf_mbbs_ls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
