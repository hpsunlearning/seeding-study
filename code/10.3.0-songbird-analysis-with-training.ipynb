{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import qiime2 as q2\n",
    "import pandas as pd\n",
    "from biom import Table, load_table\n",
    "from biom.util import biom_open\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running songbird\n",
    "\n",
    "This is best done on a compute cluster but the scripts are provided in `diff-analysis-new/songbird-helper-new.py`. From these grid searches we determined the best perams. to run songbird with with a $Q^{2}$-value close to one. From these runs we can use the differentials to explore what microbes change between the birth-modes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture the grid search results at individual time points without country as covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# for each body site repeat \n",
    "all_grid_results = {}\n",
    "input_path = '../data/diff-analysis-new/songbird-grid-search/'\n",
    "model_name = ['TP-w-training']\n",
    "days = [\"2.0\", \"30.0\", \"120.0\", \"180.0\"]\n",
    "\n",
    "for model_ in model_name:\n",
    "    # get all body site path(s)\n",
    "    partition_path = os.path.join(input_path, model_, 'Baby*.0')\n",
    "    body_sites = [bs_.split('/')[-1]\n",
    "                      for bs_ in glob.glob(partition_path)]\n",
    "    # run for each body site\n",
    "    for body_site_ in body_sites:\n",
    "        # get all baseline models CV\n",
    "        baseline_ls_path =  os.path.join(input_path, model_, body_site_, '1*')\n",
    "        baseline_models = glob.glob(baseline_ls_path)\n",
    "        # because of the maximum number of testing samples are set, \n",
    "        # sometimes it is not possible to try bigger batch_size,\n",
    "        # therefore no output\n",
    "        baseline_models = {tuple(id_.split('/')[-1].split('-')[1:]):id_\n",
    "                           for id_ in baseline_models \n",
    "                           if os.path.exists(os.path.join(id_, 'differentials.tsv'))}\n",
    "        # retrieve all baseline models\n",
    "        for id_, path_ in baseline_models.items():\n",
    "            # get path to data\n",
    "            event_acc = EventAccumulator(path_)\n",
    "            event_acc.Reload()\n",
    "            # get scalar perams\n",
    "            w_times, step_nums, vals = zip(*event_acc.Scalars('accuracy/cv_error'))\n",
    "            baseline_models[id_] = [w_times, step_nums, vals]\n",
    "        # get all fomrula based models CV\n",
    "        all_ls_path =  os.path.join(input_path, model_, body_site_, '*')\n",
    "        formula_models = glob.glob(all_ls_path)\n",
    "        exclude_ = glob.glob(baseline_ls_path)\n",
    "        formula_models = sorted(set(formula_models) - set(exclude_))\n",
    "        formula_models = {tuple(id_.split('/')[-1].split('-')[:]):id_\n",
    "                          for id_ in formula_models}\n",
    "        formula_models = {('-'.join(k[:-3]),k[-3],k[-2],k[-1]):v\n",
    "                          for k,v in formula_models.items() \n",
    "                          if os.path.exists(os.path.join(v, 'differentials.tsv'))}\n",
    "        for id_, path_ in formula_models.items():\n",
    "            # get path to data\n",
    "            event_acc = EventAccumulator(path_)\n",
    "            event_acc.Reload()\n",
    "            # get scalar perams\n",
    "            w_times, step_nums, vals = zip(*event_acc.Scalars('accuracy/cv_error'))\n",
    "            # calc q^2-value\n",
    "            base_cv = np.mean(baseline_models[id_[1:]][-1][-10:])\n",
    "            form_cv = np.mean(vals[-10:])\n",
    "            q_squared = 1 - form_cv/base_cv\n",
    "            formula_models[id_] = [form_cv, base_cv, q_squared]\n",
    "        # make dataframe to save\n",
    "        gird_results = pd.DataFrame(formula_models).T.reset_index()\n",
    "        gird_results.columns = ['formula', 'min_features', 'batch_size',\n",
    "                                'differential_prior', 'CV', 'baseline_CV',\n",
    "                                'q_squared']\n",
    "        all_grid_results[(model_, body_site_)] = gird_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formula</th>\n",
       "      <th>min_features</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>differential_prior</th>\n",
       "      <th>CV</th>\n",
       "      <th>baseline_CV</th>\n",
       "      <th>q_squared</th>\n",
       "      <th>body_site</th>\n",
       "      <th>days</th>\n",
       "      <th>model</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(birth_mode_ms, Treatment(\"Vag\")) + country</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>287.621964</td>\n",
       "      <td>347.021942</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>Baby-Feces</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TP-w-training</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C(birth_mode_ms, Treatment(\"Vag\"))</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>344.643307</td>\n",
       "      <td>347.021942</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>Baby-Feces</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TP-w-training</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         formula min_features batch_size  \\\n",
       "2   C(birth_mode_ms, Treatment(\"Vag\")) + country            3          7   \n",
       "10            C(birth_mode_ms, Treatment(\"Vag\"))            3          7   \n",
       "\n",
       "   differential_prior          CV  baseline_CV  q_squared   body_site days  \\\n",
       "2                0.25  287.621964   347.021942   0.171171  Baby-Feces  2.0   \n",
       "10               0.25  344.643307   347.021942   0.006854  Baby-Feces  2.0   \n",
       "\n",
       "            model best  \n",
       "2   TP-w-training  Yes  \n",
       "10  TP-w-training  Yes  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all models\n",
    "all_grid_df = pd.concat(all_grid_results).reset_index().drop('level_2', axis=1)\n",
    "all_grid_df[['body_site', 'days']] = all_grid_df.level_1.str.rsplit(pat = \"-\", n = 1, expand = True)\n",
    "all_grid_df['model'] = all_grid_df.level_0\n",
    "# allowed models, aka. q2>0\n",
    "all_grid_df_allowed = all_grid_df.drop(['level_0', 'level_1'], axis = 1)[all_grid_df.q_squared > 0].copy()\n",
    "ind_ = all_grid_df_allowed.groupby(['body_site','days','formula'])[['CV']].idxmin().values\n",
    "all_grid_df_allowed['best'] = np.nan\n",
    "all_grid_df_allowed.loc[ind_.flatten(), 'best'] = 'Yes'\n",
    "all_grid_df_allowed.to_csv('../data/diff-analysis-new/TP-w-training-grid-search-all-allowed-models2.tsv', sep='\\t')\n",
    "all_grid_df_allowed.loc[all_grid_df_allowed.best=='Yes', :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-120.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-4-16-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-120.0/1-4-16-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-180.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-4-8-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-180.0/1-4-8-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-2.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-3-7-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-2.0/1-3-7-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-30.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-7-28-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Feces-30.0/1-7-28-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-120.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-2-4-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-120.0/1-2-4-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-180.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-2-4-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-180.0/1-2-4-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-2.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-3-6-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-2.0/1-3-6-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-30.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-4-17-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Forearm-30.0/1-4-17-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-120.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-2-4-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-120.0/1-2-4-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-180.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-2-9-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-180.0/1-2-9-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-2.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-3-15-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-2.0/1-3-15-0.25\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-30.0/C(birth_mode_ms, Treatment(\"Vag\")) + country + baby_sex-4-9-0.5\n",
      "../data/diff-analysis-new/songbird-optimized-models/TP-model-w-country-sex/Baby-Mouth-30.0/1-4-9-0.5\n"
     ]
    }
   ],
   "source": [
    "file_path_ = '../data/diff-analysis-new/songbird-grid-search/'\n",
    "file_path_copy_ = '../data/diff-analysis-new/songbird-optimized-models/' \n",
    "\n",
    "all_grid_df_best = all_grid_df_allowed.loc[all_grid_df_allowed.best=='Yes', :]\n",
    "\n",
    "paths_copy_ = [(os.path.join(file_path_, md_, '-'.join([bs_, k_]),\n",
    "                             '-'.join(df2_.values[0][0:4])),\n",
    "                os.path.join(file_path_copy_, md_, '-'.join([bs_, k_]),\n",
    "                             '-'.join(df2_.values[0][0:4])),\n",
    "                os.path.join(file_path_, md_, '-'.join([bs_, k_]),\n",
    "                             '1-' + '-'.join(df2_.values[0][1:4])),\n",
    "                os.path.join(file_path_copy_, md_, '-'.join([bs_, k_]),\n",
    "                             '1-' + '-'.join(df2_.values[0][1:4])))\n",
    "               for md_, mddf_ in all_grid_df_best.groupby('model')\n",
    "               for bs_, bsdf_ in mddf_.groupby('body_site')\n",
    "               for k_, df_ in bsdf_.groupby('days')\n",
    "               for k2_, df2_ in df_.groupby('formula')]\n",
    "# copy the paths\n",
    "for copy_ in paths_copy_:\n",
    "    if not os.path.exists(copy_[1]):\n",
    "        shutil.copytree(copy_[0], copy_[1])\n",
    "        print(copy_[1])\n",
    "    if not os.path.exists(copy_[3]):\n",
    "        shutil.copytree(copy_[2], copy_[3])\n",
    "        print(copy_[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from skbio.stats.composition import (alr_inv, alr,\n",
    "                                     closure, clr)\n",
    "# warnings filter \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import taxonomy\n",
    "taxdf = q2.Artifact.load('../data/processed-data/taxonomy.qza'\n",
    "                        ).view(q2.Metadata).to_dataframe()\n",
    "\n",
    "def split_taxonomy(taxonomy):\n",
    "    feat_map = dict(taxonomy.Taxon)\n",
    "    taxonomy['Taxon'] = [feat_map[feat]\n",
    "                         if feat in feat_map.keys()\n",
    "                         else np.nan\n",
    "                         for feat in taxonomy.index]\n",
    "    # add taxonomic levels for grouping later (if available)\n",
    "\n",
    "    def tax_split(tax_id, tax_level): return tax_id.split(\n",
    "        tax_level)[1].split(';')[0]\n",
    "\n",
    "    for level, lname in zip(['k__', 'p__', 'c__', 'o__',\n",
    "                             'f__', 'g__', 's__'],\n",
    "                            ['kingdom', 'phylum', 'class',\n",
    "                             'order', 'family', 'genus',\n",
    "                             'species']):\n",
    "        if lname not in taxonomy.columns:\n",
    "            taxonomy_tmp = []\n",
    "            for tax in taxonomy.Taxon:\n",
    "                if tax is not np.nan and\\\n",
    "                   level in tax and\\\n",
    "                   len(tax_split(tax, level)) > 0:\n",
    "                    taxonomy_tmp.append(tax_split(tax,\n",
    "                                                  level))\n",
    "                else:\n",
    "                    taxonomy_tmp.append(np.nan)\n",
    "            taxonomy[lname] = taxonomy_tmp\n",
    "    return taxonomy\n",
    "\n",
    "# split the levels into columns\n",
    "taxdf = split_taxonomy(taxdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_differentials(clr_diff):\n",
    "    \"\"\" re-centers data around zero \"\"\"\n",
    "    \n",
    "    # center again around zero after completion\n",
    "    clr_diff = clr_diff \\\n",
    "                - clr_diff.mean(axis=0).values\n",
    "    clr_diff = clr_diff \\\n",
    "                - clr_diff.mean(axis=1).values.reshape(-1, 1)\n",
    "    # return the re-centered data\n",
    "    return clr_diff\n",
    "\n",
    "def differentials_to_probability(differentials,\n",
    "                                 numerators,\n",
    "                                 prefix='C(birth_mode, Treatment(\"CS\"))',\n",
    "                                 basis_name=\"P(CS)\"):\n",
    "    \"\"\" converts differentials to something like\n",
    "        a probability using the inverse-alr transform.\n",
    "    \"\"\"\n",
    "    # first recenter the differentials\n",
    "    differentials = center_differentials(differentials)\n",
    "    # then take the inverse alr\n",
    "    prob_differentials = alr_inv(differentials[numerators])\n",
    "    # make a dataframe to return \n",
    "    columns = [col.replace(\"[T.\",\"P(\").replace(\"]\",\")\").replace(prefix, \"\")\n",
    "                for col in numerators] # rename cols\n",
    "    columns = [basis_name] + columns\n",
    "    prob_differentials = pd.DataFrame(prob_differentials,\n",
    "                                      differentials.index,\n",
    "                                      columns)\n",
    "    return prob_differentials\n",
    "\n",
    "# container for differentials\n",
    "all_differentials = {}\n",
    "all_metadata = {}\n",
    "all_tables = {}\n",
    "# get path info\n",
    "data_path = '../data/diff-analysis-new'\n",
    "model_name = ['TP-model-no-country', 'TP-model-w-country']\n",
    "diffs_use = ['[T.CS]', '[T.CSseed]']\n",
    "\n",
    "for model_ in model_name:\n",
    "    input_path = ('../data/diff-analysis-new/songbird-optimized-models/' \n",
    "                  + model_)\n",
    "    # add a frequency filter\n",
    "    min_freq = 0.0\n",
    "    # get all body site path(s)\n",
    "    partition_path = os.path.join(input_path, 'Baby*')\n",
    "    body_sites = [bs_.split('/')[-1]\n",
    "                      for bs_ in glob.glob(partition_path)]\n",
    "    # run for each body site\n",
    "    for body_site_ in body_sites:\n",
    "        # for body site subsets\n",
    "        sub_path = os.path.join(input_path, body_site_, '*')\n",
    "\n",
    "        # get differentials\n",
    "        baseline_ls_path = os.path.join(input_path, body_site_, '1*')\n",
    "        formula_models = glob.glob(sub_path)\n",
    "        exclude_ = glob.glob(baseline_ls_path)\n",
    "        formula_models = sorted(set(formula_models) - set(exclude_))[0]\n",
    "        # get diffs. and add taxonomy labels\n",
    "        diff = pd.read_csv(os.path.join(formula_models, 'differentials.tsv'),\n",
    "                           sep='\\t', index_col=0)\n",
    "        # get table and metadata for each subset\n",
    "        data_split_path = os.path.join(data_path, body_site_)\n",
    "        mf = pd.read_csv(os.path.join(data_split_path,\n",
    "                                      'metadata.tsv'),\n",
    "                           sep='\\t', index_col=0)\n",
    "        bt = load_table(os.path.join(data_split_path,\n",
    "                                     'table.biom'))\n",
    "        # caclulate the freq. of that feature in the data, the number of times a feature appeared\n",
    "        # in the sampels\n",
    "        frequncy = pd.DataFrame(bt.matrix_data.toarray().astype(bool).sum(1) / \n",
    "                                bt.shape[1], \n",
    "                                bt.ids('observation'), ['feature-frequency']) \n",
    "        frequncy = frequncy.reindex(diff.index)\n",
    "        # add to diff to reduce files saved\n",
    "        diff['feature-frequency'] = frequncy['feature-frequency']\n",
    "        # apply the filter\n",
    "        diff = diff[diff['feature-frequency'] >= min_freq]\n",
    "        # reindex taxonomy\n",
    "        taxdf_ = taxdf.reindex(diff.index)\n",
    "        # get the prob. of each microbe in each state\n",
    "        differential_cols = [col_ for col_ in diff.columns\n",
    "                             if any(dc in col_ for dc in diffs_use)]\n",
    "        diff_ = center_differentials(diff[['Intercept'] + differential_cols])\n",
    "        diff_.columns = ['centered-' + \n",
    "                         hh.replace(\"[T\", \"diff\").replace(\"]\", \"\").replace('C(birth_mode_ms, Treatment(\"Vag\"))', \"\") \n",
    "                         for hh in diff_.columns]\n",
    "        \n",
    "        pdiff = differentials_to_probability(diff[['Intercept'] + \n",
    "                                                  differential_cols],\n",
    "                                             differential_cols, \n",
    "                                             prefix = 'C(birth_mode_ms, Treatment(\"Vag\"))',\n",
    "                                             basis_name=\"P(Vag)\")\n",
    "        pdiff = pdiff.reindex(diff.index)\n",
    "        # add all together\n",
    "        diff = pd.concat([pdiff, diff, diff_, taxdf_], axis=1)\n",
    "        # calculate seeding effectiveness metric TBA\n",
    "        diff['seeding-effectiveness'] = (diff['P(Vag)'] * diff['P(CSseed)']) + (diff['P(CS)']/4)\n",
    "        # save the files\n",
    "        all_differentials[(model_, body_site_)] = diff.rename({'P(CSseed)':'P(CS-seeded)',\n",
    "                                                                    'P(Vag)':'P(Vaginal)'}, axis=1)\n",
    "        all_metadata[(model_, body_site_)] = mf\n",
    "        all_tables[(model_, body_site_)] = bt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(all_differentials).reset_index().rename(columns = {'level_0':'model', \n",
    "                                                             'level_1':'body_site_days'}).to_csv(\n",
    "    os.path.join(data_path, 'TP-all-countries-best-model-processed.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
